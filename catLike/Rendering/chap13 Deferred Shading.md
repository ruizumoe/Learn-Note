# 延迟渲染

延迟渲染相比于前向渲染的区别在于
+ 前向渲染，需要着色器获取网格数据，然后转化到正确的裁剪空间，然后插值计算，并根据顶点和片元着色器推导表面数据，计算光照。**每个物体会逐像素光源重复这一步骤**。叠加通道虽然不需要添加深度缓冲和简介光照，但是也要执行上述步骤。
+ 延迟渲染是在基础通道中，就把网格的几何属性记录到缓冲区中，让叠加通道复用这些属性，因此也被叫做几何通道。在基础通道中，只关心几何属性，所有**直接光照计算都可以推迟到逐个渲染光源时进行**，也就是**光照通道**。

延迟渲染优点：
1. 如果是单个光源，延迟渲染没有任何优势，但是当光源多的时候，只要光源不投射阴影，每增加一个光源只需额外处理少量工作。
2. 此外，几何体和光源分别渲染时，物体可受光照影响的光源数量没有限制。


## 渲染光源

几何通道会将世界中物体的几何信息渲染到一组特殊的纹理中，其中包括
+ 深度值
+ 世界空间法线
+ 漫反射颜色
+ 高光系数和光滑度
+ 。。。等等属性

在光照通道中，由于没有物体这一概念，光照信息拿到的只是一个充满数据的纹理（G-Buffer），因此其要对屏幕上的每一个像素进行光照计算。

因此基于不同的光源，有不同的对像素进行着色的方式

### 平行光光源

由于平行光没有位置，只有方向，理论上世界上所有位置都可以被平行光照亮。

因此对于平行光，一个简单的做法就是，渲染一个覆盖整个视口的纹理，这个纹理需要逐G-buffer纹理的每一个像素，去渲染信息。 其过程为
+ 获得视口纹理的屏幕坐标(x,y)
+ 基于屏幕纹理，采样G-buffer中的每一个像素信息
+ 基于深度和屏幕位置，通过逆投影变化，重建出点在世界空间的位置
+ 计算光照
+ 根据光照模型，计算出该像素的光照颜色，然后输出最终的渲染目标

### 点光源和聚光灯

由于这两种灯光需要控制范围和距离，因此需要使用使用**光照体积**来确定哪些像素需要被着色

通常光照体积就是一个简单的几何性质
+ 点光源 一个二十面球体，球心是光源，半径为光源的range
+ 聚光灯 一个金字塔或者平截头体，追尖是光源位置，角度和方向由灯光位置和方向确定

在光照通道中，其具体渲染光照体积的过程为

1. 首先在顶点着色器中，对光照的顶点进行MVP变化计算，从而得到的光照体积在世界空间中覆盖的内容
2. 执行光栅化，将光照体积的内容光栅化到屏幕上，**只有被这个物体覆盖的像素（片段）才会进入片段着色器执行**。
3. 执行片元着色器，进入该着色器，表明该像素确定被执行到了光照。
   1. 获得有光照的像素的uv信息
   2. 采样G-Buffer内容
   3. 计算光照
   4. 输出光照颜色

> P3R使用的就是延迟着色，其几何阶段计算出模型内容，但是实际是有漫反射颜色的，只是这些颜色由于没有光照，特别暗。然后在光照阶段才开始计算光照。

## 几何缓冲区

延迟着色一般需要四个G-buffer.对于 LDR，它们的组合大小为每像素 160 位；对于 HDR，则为每像素 192 位。

以下是一个简单例子（可以不按这个方式去实现）

```hlsl
struct FragmentOutput {
	#if defined(DEFERRED_PASS)
		float4 gBuffer0 : SV_Target0;
		float4 gBuffer1 : SV_Target1;
		float4 gBuffer2 : SV_Target2;
		float4 gBuffer3 : SV_Target3;
	#else
		float4 color : SV_Target;
	#endif
};
```

### 缓冲区0

第一个缓冲区用于存储漫反射反照率和表面遮挡。反照率存储在 RGB 通道中，遮挡存储在 A 通道中。此时我们已知反照率颜色，并可通过 GetOcclusion 访问遮挡值。它是一个 ARGB32 纹理

```hlsl
output.gBuffer0.rgb = albedo;
output.gBuffer0.a = GetOcclusion(i);
```


### 缓冲区1

第二个 G 缓冲用于在 RGB 通道中存储高光颜色，并在 A 通道中存储平滑度值，是一个 ARGB32 纹理。

```hlsl
output.gBuffer0.rgb = albedo;
output.gBuffer0.a = GetOcclusion(i);
output.gBuffer1.rgb = specularTint;
output.gBuffer1.a = GetSmoothness(i);
```

### 缓冲区2

第三个 G 缓冲区包含世界空间法线向量。存储在ARGB2101010 纹理的 RGB 通道中。也就是说每一个坐标用了10位来存储，而A通道只用了2位。

```hlsl
output.gBuffer1.rgb = specularTint;
output.gBuffer1.a = GetSmoothness(i);
output.gBuffer2 = float4(i.normal * 0.5 + 0.5, 1);
```

### 缓冲区3

最终的 G 缓冲用于累积场景的光照。其格式取决于相机设置为 LDR 还是 HDR 模式。

```hlsl
output.gBuffer2 = float4(i.normal * 0.5 + 0.5, 1);
output.gBuffer3 = color;
```

# 延迟反射

延迟渲染模式的不同之处在于，探针不是按物体混合，而是按像素混合。

+ 按物体混合：渲染物体的时候，根据使用的反射探针，整个物体都基于探针信息进行着色
  + 一般来说，一个物体可能在很多个反射探针的影响范围内，但是代码只会使用一个反射探针
  + 因此其会出现，如果两个物体特别近，但是由于处于不同反射探针范围，从而导致不连续。
+ 按像素混合：根据屏幕像素在世界空间中的位置，混合所有影响该位置的反射探针
  + 步骤
    + 反射探针的影响体积和索引信息会被编码到一个特殊的屏幕空间纹理中
    + 在光照阶段，对每个像素采样G-Buffer内容，
    + 查询哪些反射探针会影响到该像素
    + 根据**查询的权重，实时对多个探针采样的内容进行混合**
    + 应用反射
  + 优点：不会产生突兀的过度，反射想过也更加精确，性能更高